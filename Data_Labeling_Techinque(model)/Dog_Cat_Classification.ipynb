{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "data_dir = r\"D:\\Prodigal\\Pytorch_onnx\\DataSets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: D:\\Prodigal\\Pytorch_onnx\\DataSets\n"
     ]
    }
   ],
   "source": [
    "# Print dataset path\n",
    "print(\"Dataset directory:\", data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory exists: True\n",
      "Test directory exists: True\n",
      "Contents of dataset folder: ['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Print subdirectories (train/test)\n",
    "print(\"Train directory exists:\", os.path.exists(os.path.join(data_dir, \"train\")))\n",
    "print(\"Test directory exists:\", os.path.exists(os.path.join(data_dir, \"test\")))\n",
    "\n",
    "# List contents of the dataset folder\n",
    "print(\"Contents of dataset folder:\", os.listdir(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Subdirectories: ['Cats', 'Dogs']\n",
      "Test Subdirectories: ['Cats', 'Dogs']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Subdirectories:\", os.listdir(os.path.join(data_dir, \"train\")) if os.path.exists(os.path.join(data_dir, \"train\")) else \"Train folder missing\")\n",
    "print(\"Test Subdirectories:\", os.listdir(os.path.join(data_dir, \"test\")) if os.path.exists(os.path.join(data_dir, \"test\")) else \"Test folder missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in Train Cats: 4\n",
      "Images in Train Dogs: 4\n"
     ]
    }
   ],
   "source": [
    "train_cats_path = os.path.join(data_dir, \"train\", \"cats\")\n",
    "train_dogs_path = os.path.join(data_dir, \"train\", \"dogs\")\n",
    "\n",
    "print(\"Images in Train Cats:\", len(os.listdir(train_cats_path)) if os.path.exists(train_cats_path) else \"Missing\")\n",
    "print(\"Images in Train Dogs:\", len(os.listdir(train_dogs_path)) if os.path.exists(train_dogs_path) else \"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid files in Train Cats: []\n",
      "Invalid files in Train Dogs: []\n"
     ]
    }
   ],
   "source": [
    "valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\")\n",
    "\n",
    "print(\"Invalid files in Train Cats:\", [f for f in os.listdir(train_cats_path) if not f.lower().endswith(valid_extensions)] if os.path.exists(train_cats_path) else \"Missing\")\n",
    "print(\"Invalid files in Train Dogs:\", [f for f in os.listdir(train_dogs_path) if not f.lower().endswith(valid_extensions)] if os.path.exists(train_dogs_path) else \"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Prodigal\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Prodigal\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the optimizer (Make sure model is defined)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Use Adam or SGD\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()  # For classification problems\n",
    "\n",
    "# Training loop\n",
    "for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    outputs = model(images)  # Forward pass\n",
    "    loss = criterion(outputs, labels)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  # Choose optimal epochs\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0001\n",
      "Epoch 2/10, Loss: 0.0000\n",
      "Epoch 3/10, Loss: 0.0000\n",
      "Epoch 4/10, Loss: 0.0000\n",
      "Epoch 5/10, Loss: 0.0000\n",
      "Epoch 6/10, Loss: 0.0000\n",
      "Epoch 7/10, Loss: 0.0000\n",
      "Epoch 8/10, Loss: 0.0000\n",
      "Epoch 9/10, Loss: 0.0000\n",
      "Epoch 10/10, Loss: 0.0000\n",
      "Final train_losses: [5.825615517096594e-05, 1.0430809993522416e-07, 1.4901160305669237e-08, 1.4901160305669237e-08, 1.4901160305669237e-08, 2.9802318834981634e-08, 4.470347647611561e-08, 5.960463056453591e-08, 8.940693874137651e-08, 1.3411037969035533e-07]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []  # Store training losses\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)  # Compute average loss\n",
    "    train_losses.append(epoch_loss)  # ✅ Append to list\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Debug print before plotting\n",
    "print(f\"Final train_losses: {train_losses}\") \n",
    "\n",
    "# ✅ Ensure x and y values match\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', label='Training Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create directory if it does not exist\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"./models/resnet50_dog_cat.pth\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure models directory exists\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create dummy input on the same device as the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Move to GPU if available\n",
    "\n",
    "# Export model to ONNX\n",
    "torch.onnx.export(model, dummy_input, \"./models/resnet50_dog_cat.onnx\", \n",
    "                  input_names=[\"input\"], output_names=[\"output\"], \n",
    "                  dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}})\n",
    "\n",
    "print(\"ONNX model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model file found at: d:\\Prodigal\\Pytorch_onnx\\Sandip\\Pytorch\\models\\resnet50_dog_cat.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL_PATH = \"models/resnet50_dog_cat.pth\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"❌ Model file not found at: {os.path.abspath(MODEL_PATH)}\")\n",
    "else:\n",
    "    print(f\"✅ Model file found at: {os.path.abspath(MODEL_PATH)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
